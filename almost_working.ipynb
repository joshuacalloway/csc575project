{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "almost-working.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEg7dlOdMA+894SRnUR5r2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27d5b00a90ec4dc2aa636306a0fbb906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09caa22316b546389de51a20de4ad854",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_288e7b455f65417b835cc2196a9249eb",
              "IPY_MODEL_a221c31d02c94592acef6da166166c9f"
            ]
          }
        },
        "09caa22316b546389de51a20de4ad854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "288e7b455f65417b835cc2196a9249eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_365d4afd68cc483897f01cc9ebc64cf3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_848c475166264af897028d13ea13426b"
          }
        },
        "a221c31d02c94592acef6da166166c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52c367331aac4ddd8baf388abcd3602d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [16:16&lt;00:00,  9.76s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63d7b22ba520434aa3a3e49296ed03e6"
          }
        },
        "365d4afd68cc483897f01cc9ebc64cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "848c475166264af897028d13ea13426b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52c367331aac4ddd8baf388abcd3602d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63d7b22ba520434aa3a3e49296ed03e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuacalloway/csc575project/blob/main/almost_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw0ki1i8P-Or",
        "outputId": "9b72dbeb-0aec-401d-e5be-7532e2e9de8c"
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "export CUDA_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8FjkIWPQQ3W",
        "outputId": "c6bb96f4-3c8e-4671-eb5d-840b5bf31f3c"
      },
      "source": [
        "!sh setup.sh\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'apex' already exists and is not an empty directory.\n",
            "/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-jeq9pq0k\n",
            "Created temporary directory: /tmp/pip-req-tracker-ornx3p5o\n",
            "Created requirements tracker '/tmp/pip-req-tracker-ornx3p5o'\n",
            "Created temporary directory: /tmp/pip-install-6g5b_wjn\n",
            "Processing ./apex\n",
            "  Created temporary directory: /tmp/pip-req-build-nn07nmzc\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-ornx3p5o'\n",
            "    Running setup.py (path:/tmp/pip-req-build-nn07nmzc/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.8.0+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-nn07nmzc/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-nn07nmzc/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-nn07nmzc/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-nn07nmzc/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-nn07nmzc/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-nn07nmzc/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-nn07nmzc/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-nn07nmzc has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-ornx3p5o'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-kpjwv3jn\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-nn07nmzc/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-nn07nmzc/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-kpjwv3jn/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.8.0+cu101\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-nn07nmzc/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "    Cuda compilation tools, release 10.1, V10.1.243\n",
            "    from /usr/local/cuda-10.1/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.7\n",
            "    creating build/lib.linux-x86_64-3.7/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.7/apex\n",
            "    creating build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.7/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.7/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "    copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "    copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    running build_ext\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:369: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.7\n",
            "    creating build/temp.linux-x86_64-3.7/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:44:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         return tensors[0].type();\n",
            "                                ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/amp_C_frontend.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/amp_C.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.7/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/syncbn.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/welford.cu -o build/temp.linux-x86_64-3.7/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/csrc/syncbn.o build/temp.linux-x86_64-3.7/csrc/welford.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/syncbn.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'mlp_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.7/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "                                                                                 ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                        ^\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                               \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                               \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.7m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/csrc/mlp.o build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/mlp_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    copying build/lib.linux-x86_64-3.7/mlp_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.7/syncbn.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.7/amp_C.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/reparameterization/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.7/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.7/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/distributed.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/multiproc.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/LARC.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/normalization/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/normalization\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.7/apex/RNN/models.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.7/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.7/apex/RNN/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.7/apex/RNN/cells.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/layer_norm/layer_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/layer_norm/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.7/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.7/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.7/apex/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/mlp/mlp.py -> /usr/local/lib/python3.7/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/mlp/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/mlp\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/pyprof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/base.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/output.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/data.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/db.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/_initialize.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/rnn_compat.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/scaler.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/compat.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/wrap.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/lists/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/__version__.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/handle.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/amp.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/_amp_state.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/opt.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/utils.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/frontend.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/distributed.py to distributed.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/LARC.py to LARC.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/normalization/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/models.py to models.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/cells.py to cells.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/mlp/mlp.py to mlp.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/mlp/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/base.py to base.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/output.py to output.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/data.py to data.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/db.py to db.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/_initialize.py to _initialize.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/scaler.py to scaler.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/compat.py to compat.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/wrap.py to wrap.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/__version__.py to __version__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/handle.py to handle.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/amp.py to amp.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/opt.py to opt.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/utils.py to utils.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/frontend.py to frontend.cpython-37.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.7/dist-packages/apex-0.1-py3.7.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-kpjwv3jn/install-record.txt'\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "  Removing source in /tmp/pip-req-build-nn07nmzc\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-ornx3p5o'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RhcKIO-QWYR",
        "outputId": "93d58984-2473-4102-9409-4659df382a84"
      },
      "source": [
        "!pip install fast-bert"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fast-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/c0/639002138d128d3462bfcf75858904ffeef8b29def6dac226e745c18440d/fast_bert-1.9.7-py3-none-any.whl (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.7MB/s \n",
            "\u001b[?25hCollecting python-box\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/55/b81be1c1456d93db93905b364d19cac5dde22fb8f442b42d41087c2fe28f/python_box-5.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fast-bert) (1.1.5)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 6.1MB/s \n",
            "\u001b[?25hCollecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: fastprogress in /usr/local/lib/python3.7/dist-packages (from fast-bert) (1.0.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from fast-bert) (8.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fast-bert) (3.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from fast-bert) (2.2.4)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/59/68c7e3833f535615fb97d33ffcb7b30bbf62bc7477a9c59cd19ad8535d72/tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 13.4MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from fast-bert) (0.0)\n",
            "Collecting pytorch-lamb\n",
            "  Downloading https://files.pythonhosted.org/packages/43/98/3bce14a319317a2856db722f2542d329baf42845fa53563d0d749c5a2d40/pytorch_lamb-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fast-bert) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fast-bert) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->fast-bert) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX->fast-bert) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->fast-bert) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->fast-bert) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->fast-bert) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->fast-bert) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->fast-bert) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->fast-bert) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fast-bert) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fast-bert) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fast-bert) (2.4.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fast-bert) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fast-bert) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fast-bert) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fast-bert) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fast-bert) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fast-bert) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fast-bert) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->fast-bert) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->fast-bert) (54.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->fast-bert) (1.1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->fast-bert) (0.22.2.post1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-lamb->fast-bert) (0.9.0+cu101)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lamb->fast-bert) (1.8.0+cu101)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->fast-bert) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->fast-bert) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->fast-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->fast-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->fast-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->fast-bert) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fast-bert) (3.7.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->fast-bert) (1.4.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-lamb->fast-bert) (7.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-lamb->fast-bert) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fast-bert) (3.4.1)\n",
            "Building wheels for collected packages: seqeval, sacremoses\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=50fdea5b17e2efcc785b8cf18049eae60b4a14a542388ba28755db8cb1477abd\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=90119ed61966b80d81669ced9a387dc7492a0c2cd7695699e7e3f85421964da4\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built seqeval sacremoses\n",
            "Installing collected packages: python-box, tensorboardX, sacremoses, tokenizers, sentencepiece, transformers, seqeval, pytorch-lamb, fast-bert\n",
            "Successfully installed fast-bert-1.9.7 python-box-5.3.0 pytorch-lamb-1.0.0 sacremoses-0.0.43 sentencepiece-0.1.95 seqeval-1.2.2 tensorboardX-2.1 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgVspW3jSfCp"
      },
      "source": [
        "from fast_bert.data_cls import BertDataBunch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rrw4wCx1SsMl"
      },
      "source": [
        "DATA_PATH='./'\n",
        "LABEL_PATH='./'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_PZC_nCSu91"
      },
      "source": [
        "databunch = BertDataBunch(DATA_PATH, LABEL_PATH,\n",
        "                          tokenizer='bert-base-uncased',\n",
        "                          train_file='train.csv',\n",
        "                          val_file='val.csv',\n",
        "                          label_file='labels.csv',\n",
        "                          text_col='text',\n",
        "                          label_col='label',\n",
        "                          batch_size_per_gpu=16,\n",
        "                          max_seq_length=512,\n",
        "                          multi_gpu=True,\n",
        "                          multi_label=False,\n",
        "                          model_type='bert')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGhRzp6DTWR7"
      },
      "source": [
        "import torch\n",
        "OUTPUT_DIR='./output'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yztU5f5WS5LL",
        "outputId": "88478b5c-3ecf-4132-f7af-423ef57e1194"
      },
      "source": [
        "from fast_bert.learner_cls import BertLearner\n",
        "from fast_bert.metrics import accuracy\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger()\n",
        "device_cuda = torch.device(\"cuda\")\n",
        "metrics = [{'name': 'accuracy', 'function': accuracy}]\n",
        "\n",
        "learner = BertLearner.from_pretrained_model(\n",
        "\t\t\t\t\t\tdatabunch,\n",
        "\t\t\t\t\t\tpretrained_path='bert-base-uncased',\n",
        "\t\t\t\t\t\tmetrics=metrics,\n",
        "\t\t\t\t\t\tdevice=device_cuda,\n",
        "\t\t\t\t\t\tlogger=logger,\n",
        "\t\t\t\t\t\toutput_dir=OUTPUT_DIR,\n",
        "\t\t\t\t\t\tfinetuned_wgts_path=None,\n",
        "\t\t\t\t\t\twarmup_steps=500,\n",
        "\t\t\t\t\t\tmulti_gpu=True,\n",
        "\t\t\t\t\t\tis_fp16=True,\n",
        "\t\t\t\t\t\tmulti_label=False,\n",
        "\t\t\t\t\t\tlogging_steps=50)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "27d5b00a90ec4dc2aa636306a0fbb906",
            "09caa22316b546389de51a20de4ad854",
            "288e7b455f65417b835cc2196a9249eb",
            "a221c31d02c94592acef6da166166c9f",
            "365d4afd68cc483897f01cc9ebc64cf3",
            "848c475166264af897028d13ea13426b",
            "52c367331aac4ddd8baf388abcd3602d",
            "63d7b22ba520434aa3a3e49296ed03e6"
          ]
        },
        "id": "UVuQ3llDTmva",
        "outputId": "c9dfbb9f-36c2-4c5e-8190-a69a124f6fa0"
      },
      "source": [
        "learner.lr_find(start_lr=1e-5,optimizer_type='lamb')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27d5b00a90ec4dc2aa636306a0fbb906",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/apex/amp/wrap.py:101: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  return orig_fn(arg0, *args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
            "\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEMCAYAAADJQLEhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3icdZ338fd3cmzObZKmbdqmB1pKKZRCERDEooAV5eBpFWF3VRR1V911n8dn3Wt11V2fZffaS11ZVOzuw7K6CAKrUqAqWg4VBaTl1JaWEtJT2rSZJG0Ok3Pm+/wxkxpK0k7b3LknM5/Xdc2VzNz3zP3Nj5JPfvf9u38/c3dERCR7RcIuQEREwqUgEBHJcgoCEZEspyAQEclyCgIRkSynIBARyXKBBYGZ3WFmzWa2ZYzt5Wb2oJm9aGZbzeyjQdUiIiJjC7JHcCew+hjb/xx42d2XA6uAb5hZfoD1iIjIKHKD+mB332Bm8461C1BqZgaUAG3A4PE+t6qqyufNO9bHiojI0TZt2tTi7tWjbQssCFJwG7AW2A+UAh909/jx3jRv3jw2btwYdG0iIhnFzHaPtS3Mi8XvAF4AZgHnALeZWdloO5rZzWa20cw2RqPRiaxRRCTjhRkEHwV+4gn1wE5gyWg7uvsad1/p7iurq0ft2YiIyEkKMwj2AG8HMLMa4HSgIcR6RESyUmDXCMzsbhKjgarMrBH4CpAH4O63A/8A3GlmmwED/trdW4KqR0RERhfkqKHrj7N9P3BlUMcXEZHU6M5iEZEspyAQEZkEfvXyQV6LdgXy2QoCEZE0NxR3/uyuTdy3sTGQz1cQiIikuQMdvQwMOXWVRYF8voJARCTN7W6NAVA3TUEgIpKV9rR2AzBHQSAikp32tHWTGzFmVUwJ5PMVBCIiaW53Wzezp04hJ2KBfL6CQEQkze1t62ZuZXFgn68gEBFJc7tbu5k7LZjTQqAgEBFJa+3dA7T3DFA3TT0CEZGstKctMWJobkD3EICCQEQkre1uS9xDMDegoaOgIBARSWtHegQKAhGR7LSntZuqknyKC4JbYl5BICKSxva0dQfaGwAFgYhIWtvd2k1dgPcQgIJARCRt9Q/GaWrvCWyOoWEKAhGRNLXvcA9xD27W0WEKAhGRNDU8/XSQ9xCAgkBEJG3tTQ4dVY9ARCRL7W7tpjAvQnVpQaDHURCIiKSp4aGjZsFMPz1MQSAikqYSQRDs0FFQEIiIpCV3n5CbyUBBICKSllq6+unuH6Iu4BFDoCAQEUlLeyZg1tFhgQWBmd1hZs1mtuUY+6wysxfMbKuZPRFULSIik81ErEMwLMgewZ3A6rE2mlkF8F3gGnc/E/hAgLWIiEwqu1u7MYPZU4NbonJYYEHg7huAtmPs8mHgJ+6+J7l/c1C1iIhMNntau5lZVkhBbk7gxwrzGsFiYKqZPW5mm8zsT0KsRUQkrexp656Q00IQbhDkAucB7wLeAXzZzBaPtqOZ3WxmG81sYzQancgaRURCsXuCho5CuEHQCPzS3WPu3gJsAJaPtqO7r3H3le6+srq6ekKLFBGZaD39Q0Q7+wJfh2BYmEHwAHCJmeWaWRFwAbAtxHpERNLC8IihoNchGBbYIphmdjewCqgys0bgK0AegLvf7u7bzOwXwEtAHPgPdx9zqKmISLbYM0Gzjg4LLAjc/foU9vkX4F+CqkFEZDI6cg9BFlwjEBGRUTR39pKfG6GiKG9CjqcgEBFJM9HOPqpLCgKffnqYgkBEJM1EO/sCX4xmJAWBiEiaURCIiGS5li4FgYhI1hocitMa66e6REEgIpKV2mL9uKMegYhItmru7AMUBCIiWSvapSAQEclq0eEega4RiIhkp6hODYmIZLdoZx+lhbkU5gW/MtkwBYGISBqJTvA9BKAgEBFJK8PzDE0kBYGISBqZ6OklQEEgIpJWFAQiIlmsu3+Qrr5BBYGISLZq6ewHJvYeAlAQiIikjWhXLzCx9xCAgkBEJG2EcTMZKAhERNLGcBBMLy2c0OMqCERE0kS0s4+IwbTi/Ak9roJARCRNRLv6qCwpICcyMYvWD1MQiIikiTDuKgYFgYhI2gjjZjJQEIiIpA0FgYhIFnP3UGYehQCDwMzuMLNmM9tynP3ON7NBM3t/ULWIiKS79p4BBoY8464R3AmsPtYOZpYD/DPwSIB1iIikvbBuJoMAg8DdNwBtx9nts8D/AM1B1SEiMhlkZBAcj5nVAu8BvhdWDSIi6SLalYVBAPwr8NfuHj/ejmZ2s5ltNLON0Wh0AkoTEZlYYfYIcif8iH+wErjHzACqgKvMbNDdf3b0ju6+BlgDsHLlSp/QKkVEJkBzZx8FuRFKCyb+13JoQeDu84e/N7M7gYdGCwERkWwwfA9B8o/jCRVYEJjZ3cAqoMrMGoGvAHkA7n57UMcVEZmMwrqZDAIMAne//gT2/UhQdYiITAbRzj7qKotCObbuLBYRSQNh3VUMCgIRkdANDMVpi/UrCEREslVrV3LRegWBiEh2OnIPQQjzDIGCQEQkdNGuXkA9AhGRrHVk0fqyiV20fpiCQEQkZMNBUFUysYvWD1MQiIiELNrZR/mUPApyc0I5voJARCRkYd5DAAoCEZHQRTv7QhsxBAoCEZHQhTnPECgIRERCNRR39rf3MqM8nBFDoCAQEQnVvkM99A/GWVhdHFoNCgIRkRDVRzsBOG16SWg1KAhEREJU39wFwMJqBYGISFZ6rTlGVUk+FUXh3EwGCgIRkVDVR7tC7Q2AgkBEJDTuTn1zFwtDvD4ACgIRkdC0xvpp7xngNPUIRESy05ELxZOhR2BmxWYWSX6/2MyuMbO8YEsTEclsr0UTQRDm0FFIvUewASg0s1rgEeCPgTuDKkpEJBvUN3dRlJ/DzJDWIRiWahCYu3cD7wW+6+4fAM4MriwRkcxX39zFgupiIhELtY6Ug8DMLgJuAB5OvhbOxNkiIhmiIRoL/UIxpB4Efwn8DfBTd99qZguAx4IrS0Qks8X6Btl3uCf0ewgAclPZyd2fAJ4ASF40bnH3zwVZmIhIJtvZEgPCv1AMqY8a+pGZlZlZMbAFeNnMvhBsaSIimWt46OikCQJgqbt3ANcBPwfmkxg5NCYzu8PMms1syxjbbzCzl8xss5n9zsyWn1DlIiKTWH1zFzkRo64yvOmnh6UaBHnJ+wauA9a6+wDgx3nPncDqY2zfCbzV3c8C/gFYk2ItIiKT3mvRLuqmFZGfG/59valW8H1gF1AMbDCzOqDjWG9w9w1A2zG2/87dDyWfPg3MTrEWEZFJLx3mGBqWUhC4+63uXuvuV3nCbuCycazjJhKnnEREMt7gUJxdrbG0GDEEKY4aMrNy4CvApcmXngD+Hmg/1QLM7DISQXDJMfa5GbgZYO7cuad6SBGRUO1p62ZgyNPiQjGkfmroDqAT+KPkowP4z1M9uJmdDfwHcK27t461n7uvcfeV7r6yurr6VA8rIhKqP6xKFv6FYkixRwAsdPf3jXj+NTN74VQObGZzgZ8Af+zuO07ls0REJpPXool7CNLlGkGqQdBjZpe4+5MAZnYx0HOsN5jZ3cAqoMrMGkmcWsoDcPfbgb8DKoHvmhnAoLuvPJkfQkRkMqlv7qKmrICywvSYxDnVIPgU8IPktQKAQ8CfHusN7n79cbZ/HPh4iscXEckY6bA85Uipjhp60d2XA2cDZ7v7CuBtgVYmIpKB3J2G5q60uVAMJ7hCmbt3JO8wBvirAOoREclozZ19dPYNTr4ewRjCnUBbRGQSSqc5hoaleo1gNMebYkJERJLcnbUv7ueWddvJz41w+ozSsEs64phBYGadjP4L34ApgVQkIpJhNje287UHt7Jx9yGW1ZZx24dXUFVSEHZZRxwzCNw9fSJLRGQSumXdNtb8poHK4nz++X1n8f7z5pAT8tKURzuVU0MiInIMG3ZE+f6GBj5w3my+fPXStLlv4GgKAhGRAPQPxvnqg1uZV1nE19+zjILc9F3mXUEgIhKAO367k4ZojP/86PlpHQJwasNHRURkFAfae7l1/atcfkYNl50+PexyjktBICIyzv5x3TYG485Xrl4adikpURCIiIyjp15rZe2L+/n0WxcyZ1pR2OWkREEgIjJOBobifHXtVmZPncKnVy0Mu5yUKQhERMbJ/ZsaeeVgJ19611IK89L7AvFICgIRkXEwFHfWbGjg7NnlvOPMmrDLOSEKAhGRcfDI1gPsbInxyUsXklxsa9JQEIiInCJ35/YnXmNeZRGrl80Iu5wTpiAQETlFTzW08mJjO5+4dEHazSOUCgWBiMgpuv2JBqpK8nnfubPDLuWkKAhERE7B1v3tbNgR5aMXz59UI4VGUhCIiKRgKO48tr2Zjt6B172+ZkMDxfk53HhBXUiVnTpNOicikoJfbzvIJ3+4iaL8HK49ZxY3XlhHWWEeD73UxMcunkd5UXpOMZ0KBYGISAqG1xp+57KZ/PT5fdz9+71UFucTMfjYJfNDru7U6NSQiEgKdrbEmF5awDf+aDnP/M3lfPndS6kqKeCjF89nZvnkXrlXPQIRkRTsaokxr6oYgPKiPG66ZD43TfKewDD1CEREUrCzJcb8yuKwywiEgkBE5Dg6egdojfUzv1pBcELM7A4zazazLWNsNzO71czqzewlMzs3qFpERE7FrpYYAPPUIzhhdwKrj7H9ncCi5ONm4HsB1iIictJ2JoNgfpWC4IS4+wag7Ri7XAv8wBOeBirMbGZQ9YiInKzhIKirnBwrjp2oMK8R1AJ7RzxvTL72BmZ2s5ltNLON0Wh0QooTERm2qyVGbcWUSTuFxPFMiovF7r7G3Ve6+8rq6uqwyxGRLLOztZt5VZnZG4Bwg2AfMGfE89nJ10RE0squlljGXiiGcINgLfAnydFDFwLt7t4UYj0iIm9wKNZPe89Axl4ohgDvLDazu4FVQJWZNQJfAfIA3P12YB1wFVAPdAMfDaoWEZGT1ZDhI4YgwCBw9+uPs92BPw/q+CIi4+HIPQQZHAST4mKxiEhYdrXGiBjMmaqLxSIiWWlnS4zZU4vIz83cX5eZ+5OJiIyDXa2xjL4+AAoCEZExuTs7owoCEZGsFe3qI9Y/xLwMnVpimIJARGQMu1q6gcweMQQKAhGRMQ0PHV1QVRJyJcFSEIiIjKGhJUZejjGrojDsUgKlIBARGcOulhhzphWRm5PZvyoz+6cTETkFu1ozd53ikRQEIiKjiMc9K+4hAAWBiMioDnb20jsQz/gRQ6AgEBEZ1c5o5s86OkxBICIyip2tmT/r6DAFgYhkvYGhOA+8sI9nGlpp7x4AEiOGCnIjzCzL7KGjEOB6BCIik8X3Hn+Nb/5qx5Hns8oL6RuMM6+ymEjEQqxsYigIRCSrNUS7uO2xet65bAYfPH8O25o62X6gg+1NnVx11sywy5sQCgIRyVruzpd+toWC3Ahfu/ZMppcWsur06WGXNeF0jUBEstZPntvH715r5YvvXML00sy/FjAWBYGIZKW2WD9ff/hlzp1bwfXnzw27nFApCEQkK92ybhudvYPc8t6zs+KC8LEoCEQk6zz1Wiv3bWrk5ksXcPqM0rDLCZ2CQESyyuHufr5w/4vMnVbEZ9+2KOxy0oJGDYlI1ojHnc//+AUOdvRy7ycvYkp+TtglpQX1CEQka9z2WD2PvRLl7969lBVzp4ZdTtpQEIhIVnhiR5Rv/XoH71lRy40X1oVdTloJ9NSQma0Gvg3kAP/h7v901Pa5wH8BFcl9vuju64KoZdPuNm5/ooGC3AgFuTkU5EUoyI1QmJdDYW4OhXkRpuTnUJiXw5Tkoyg/h8L8HIrzcynKz6G4IPG1IDeCWXaPMhAJw7rNTTy6vZlrls/i4tOqyElxtE/joW7+4p7nOb2mlH98z1n6//cogQWBmeUA3wGuABqBZ81srbu/PGK3LwH3uvv3zGwpsA6YF0Q9sb4hGg/10Dc4RN9AnL7BIXqTXweG/IQ+KydilBTk/uFRmEtpYS5lhXmUTcmltDCP8il5VEzJo6Ion4qiPKYW5TO1OI9pRfkZv+ydSBCG4s7XH3qZ/e293L+pkZnlhbzv3Nm8/7zZx5whtKm9hz+/6zmGhpzv3XierguMIsgewZuAendvADCze4BrgZFB4EBZ8vtyYH9QxVy6uJpLF1ePum1wKE7vYJzegSF6+ocSXweG6O5PPO/uHyLWP0hP8musb5BY3xCdvYN09Q3Q1TfIoVg/u1u76egZoL1ngMH42OEytSiPacX5VJYUML20gOmlhUwvK6C6pICaskJmlCe+lhbmBdUcIpPOY9ub2d/ey7c/dA65kQj3bdrLdx+v57bH6jmvbirvWVHLu8+eSUVRPgA7Dnby/ScaeOCFfQB894Zzs2JtgZMRZBDUAntHPG8ELjhqn68Cj5jZZ4Fi4PIA6xlTbk6EkpwIJQXj0xzuTs/AEIe6Bzjc3c/h7gEOdfdzKNZPS1c/rbE+2mL9RDv72LKvnebOZrr7h97wOcX5OdSUF1JbMYWZ5YXMqpjCrPIpzJ46hTnTiphZXqjehWSNu57ZTU1ZAe86aya5ORHedfZMDrT38tPn9/HT5xv50s+28PcPvsxlS6oZGHIe3d7MlLwcbrywjpsumc+caUVh/whpK+zho9cDd7r7N8zsIuCHZrbM3eMjdzKzm4GbAebOTf9bwc2MovxcivJzqa2YktJ7Yn2DNHf2cbCjl4MdvRxo7+VA8uv+9l5eORAl2tWHj+ho5ESMGWWFzJ1WlHhUFlFXWUTdtGLmVhZRPkU9CskMe9u6eXxHlM+9bdHr/viZUV7Ip1ct5FNvXcDW/R389Pl9PPDCfuLufP7yxfzJRXVMLc4PsfLJIcgg2AfMGfF8dvK1kW4CVgO4+1NmVghUAc0jd3L3NcAagJUrV57YCf1Jorggl/kFucfsuvYPxjnQ3kvjoW72Hupmb1sPjYe62dPWzfrtB2np6n/d/lOL8qirLGZeZRF1lcUsqC5mQVUJ86uLx633IzIR7v79HiJmfOhNc0bdbmYsqy1nWW05f3vVGQBZP23EiQjyt8GzwCIzm08iAD4EfPioffYAbwfuNLMzgEIgGmBNk1p+boS5lYm//EcT6xtkT1s3u1u72dMWY1drN7tbYzy76xAPvLj/db2J6aUFLKopYdH0UhbXlLK4poTFM0op03UJSTP9g3Hu3biXty+Zzszy4/ewFQAnLrAgcPdBM/sM8EsSQ0PvcPetZvb3wEZ3Xwv8L+DfzezzJC4cf8TdM/Iv/olQXJDLGTPLOGNm2Ru29Q4Msbu1m4ZoFw0tMV6LdlHf3MW9G/e+7vrE/KpiltWWc1ZtGWfVVnDOnAqNspBQ/XLrAVq6+rlBY/8DY5Pt9+7KlSt948aNYZeRMeJxZ397D68e7OLlpg42N7azeV87+w73AJAbSXS53zR/GufPm8ab5k2jvEi9Bpk4H/z+UzS19/L4/16lv/ZPgZltcveVo23TieIsF4kYs6cWMXtqEZct+cPKTK1dfbzU2M6zu9r4/c427vztLtZsaCBicM6cCt66eDqXLq7i7NkVKd/UI3Ki6ps7eWZnG1985xKFQIAUBDKqypICLlsy/Ug49A4M8eLew/y2voUndkT51/U7+NavdzC1KI+3LanhyjNruHRRtU4jyQmLx50n61v476d3s6etm5XzpnLRgiouWDCN/356D/k5ET5w3uywy8xoOjUkJ6Ut1s9vXo3y+CtRHt3eTHvPAIV5Ed6yqJrVZ87g8qU1Gr6aJbbsa+dnz+9j8YxSzp1bwYKqkpT+ej8U6+f+TY3c9cxudrV2M604n6Uzy3h+zyFiyetWEYOrl8/i2x9aEfSPkfF0akjG3bTifK49p5Zrz6llYCjOszvbeOTlgzyy9QC/evkgeTnGxadVcdWymVyxtEZjuTPUtqYOPvzvT9PZN3hkVFpZYS7nzJ3K4ukl1FUWMWdaYvhyjhnP7z3Ept2Jx7amDuIO58+byuevWMzqZTMoyM1hYCjOln3tPN3QxpZ97XzmstPC/SGzgHoEMq7cnZca21m3uYl1W5rY29ZDTsRYWTeVK5bW8PYzanSbf4bY3Rrj/bc/RY4Z933qIvoGh3hu92Ge33uI5/ccZmdLjL7B+BveV5yfw4q5Uzl3bgVXnT2TJTPeOMpNxt+xegQKAgmMu7N1fwc/39LE+m3NbD/QCcDC6mIuO306lyyq4oL5lbquMAk1d/Ty/tufoqN3gPs+eRGLat643GM87kS7+o7c29I3OMQ5cypYMqNMAwxCoCCQtLC3rZv12w6yfnszz+xso38wTn5OhPPqpnLJoirevLCSs2rLNX9SmmvvHuCDa55iT1s3P/rEhZwzpyLskiQFCgJJOz39Qzy7q40n61v4zastbGvqAKCkIJc3zZ/GRQsqufi0KpbMKNWwwTQxOBRn/fZmbl3/KjsOdvKfH3kTlyyqCrssSZEuFkvamZKf87qpwVu6+ni6oZWnXks8Ht2emG6qqiSfi0+r4i2LqnnLoipqygrDLDtjxfoGeeVgJzsOdJKbE2FWcrbbGeWFdPYO8uNn9/CjZ/awv72XmeWFfOfD5yoEMoh6BJKWDrT38mR9C0++GuXJ+pYjE+otmVHKpYureevialbOm0pBrq4vpGr7gQ627OvgcHd/Ylr07gGaO/p45WAHe9t6xnxfxCDu8JZFVdx4YR1vXzJdp+8mIZ0akkktHne2H+hkw6tRNuyI8uyuNgaGnCl5Oaw6vZqrl8/ibUumU5inUBjN4FCcf3u0nn979FWG10vKiRgVU/KoLMlnUU0pS2pKWTKzjNNrSol7YtqR/Yd72X+4h8GhONeuqGVhdUm4P4icEgWBZJRY3yBPN7Ty2CvN/GLLQVq6+ijOz+GKpTVcvXwWly6uJk9/sQKJtXr/8p4X2Lj7EO9dUctn376IacX5lBbk6tpLllEQSMYaHIrzzM42HnppP+s2H6C9Z4CqknyuWV7Le8+t5cxZZVm7UPm6zU188X9eIu7w9euWcd2K2rBLkhApCCQr9A/GeWJHlJ8818j6bc30D8VZMqOU61bUcvXyWSmvFjeRflvfwrO72qgeXru6tICKojxauvppau+h6XAv+9t7cE/czT38qCzOT65vXXjklFj/YJzf72zj0e3NPPZKMztbYiyfU8GtHzqHukrdxJftFASSdQ539/PQS0385LlGnttzGEhMZXDN8llcddZMKksKTunz97Z109Tey7lzK076wun+wz1c+a0NdPUNHnO/ovwcciJGZ+/o+5VPyaOmrIB9h3qI9Q+RnxvhogWVXLG0hg+eP0enyQRQEEiW29PazYMv7eeBF/ax42AXORHjwgXTuOqsmbzjzBlUnUAo7GqJcdtj9fz0+X0MxZ2pRXm848wZvPOsmbx5YWXKv3TdnZv+ayNPvdbKQ5+7hKL8HJo7+mju7ONQdz/VJQXMrChkZvkUygpzMTP6B+Mc7u6nNdZPS1cfBzv6Xre+dVVJAW9bMp2LT6ukKF8jw+X1FAQiSduaOnj4pSbWbW6ioSVGxOCC+ZWsXjaDK8+sGXMpxJ0tMb6TDIDciHHjhXWcO3cqj7x8gPXbmunqG6R8Sh7vWVHLjRfWcdr0Y4+weeCFffzFPS/w5Xcv5aZL5gfxo4q8joJA5CjuiSGp6zY38fDmJhqiMQCWzy7nyjNnsLC6hG1NHWzd386WfR0c6OilIDfCDRfU8am3LmD6iBvbegeGePLVFh54cT+/2NLEwJDz5oWV/PGFdVy+tOYNvYTWrj4u/+YT1FUW8z+ffrPm3ZEJoSAQOY765i5+ufUAj7x8kBf3Jq4pRAwWVpewrLacM2eVcc3yWa8LgNG0dPXx42f38qNn9rDvcA+1FVP4qysWc92K2iO/8D939/P8fEsTD3/uLSweZbI2kSAoCEROQFN7Dwfaezl9RulJn2sfijuPbm/m2+t3sGVfB6fXlPJ/Vp+OO3z8Bxv5/OWL+YvLF41z5SJjUxCIhCQedx7e3MQ3HnmFXa3d5EaM06aXsPYzl5Cfq9E8MnE06ZxISCIR4+rls1i9bAb3btzL/Zsa+YdrlykEJK0oCEQmQF5O4kLzDRfUhV2KyBvozxIRkSynIBARyXIKAhGRLKcgEBHJcgoCEZEspyAQEclyCgIRkSynIBARyXKTbooJM4sCu0fZVA60H+ftx9pnrG2jvX70a8d7XgW0HKe2k5HKz3wy7wmjnYJqo7FqG4/3ZFI7BdVGx9tP7ZTafqm207Harc7dq0f9dHfPiAew5lT2GWvbaK8f/VoKzzeG9TNPlnYKqo3UTuG2kdppYtsplXYb7ZFJp4YePMV9xto22utHv3a850E5meOoncbvPZnUTkG10fH2Uzultl+q7ZRKu73BpDs1NBmZ2UYfY9Y/SVAbpUbtlBq104nJpB5BOlsTdgGTgNooNWqn1KidToB6BCIiWU49AhGRLKcgEBHJcgoCEZEspyAImZkVm9lGM3t32LWkKzM7w8xuN7P7zezTYdeTrszsOjP7dzP7sZldGXY96crMFpjZ/zOz+8OuJV0oCE6Smd1hZs1mtuWo11eb2StmVm9mX0zho/4auDeYKsM3Hu3k7tvc/VPAHwEXB1lvWMapnX7m7p8APgV8MMh6wzJO7dTg7jcFW+nkolFDJ8nMLgW6gB+4+7LkaznADuAKoBF4FrgeyAFuOeojPgYsByqBQqDF3R+amOonzni0k7s3m9k1wKeBH7r7jyaq/okyXu2UfN83gLvc/bkJKn/CjHM73e/u75+o2tOZFq8/Se6+wczmHfXym4B6d28AMLN7gGvd/RbgDad+zGwVUAwsBXrMbJ27x4Ose6KNRzslP2ctsNbMHgYyLgjG6d+TAf8E/DwTQwDG79+TvJ6CYHzVAntHPG8ELhhrZ3f/WwAz+wiJHkFGhcAxnFA7JQPzvUABsC7QytLLCbUT8FngcqDczE5z99uDLC6NnOi/p0rg/wIrzOxvkoGR1RQEacDd7wy7hnTm7o8Dj4dcRtpz91uBW8OuI925eyuJ6yiSpIvF42sfMGfE89nJ1+T11E6pUTulRu10ihQE4+tZYJGZzTezfOBDwNqQa0pHaqfUqJ1So3Y6RQqCkyltvhcAAAMpSURBVGRmdwNPAaebWaOZ3eTug8BngF8C24B73X1rmHWGTe2UGrVTatROwdDwURGRLKcegYhIllMQiIhkOQWBiEiWUxCIiGQ5BYGISJZTEIiIZDkFgWQMM+ua4OP9boKPV2FmfzaRx5TsoCAQGYOZHXMuLnd/8wQfswJQEMi4UxBIRjOzhWb2CzPbZGa/MbMlydevNrNnzOx5M/u1mdUkX/+qmf3QzH4L/DD5/A4ze9zMGszscyM+uyv5dVVy+/1mtt3M7kpOCY2ZXZV8bZOZ3Wpmb1hzwsw+YmZrzexRYL2ZlZjZejN7zsw2m9m1yV3/CVhoZi+Y2b8k3/sFM3vWzF4ys68F2ZaSwdxdDz0y4gF0jfLaemBR8vsLgEeT30/lD3fWfxz4RvL7rwKbgCkjnv+OxBTYVUArkDfyeMAqoJ3EZGcRElMgXEJiwaG9wPzkfncDD41S40dITJ08Lfk8FyhLfl8F1AMGzAO2jHjflcCa5LYI8BBwadj/HfSYfA9NQy0Zy8xKgDcD9yX/QIfEL3RI/NL+sZnNBPKBnSPeutbde0Y8f9jd+4A+M2sGakj84h7p9+7emDzuCyR+aXcBDe4+/Nl3AzePUe6v3L1tuHTgH5OrccVJzLdfM8p7rkw+nk8+LwEWARvGOIbIqBQEkskiwGF3P2eUbf8GfNPd1yYXvvnqiG2xo/btG/H9EKP/f5PKPscy8pg3ANXAee4+YGa7SPQujmbALe7+/RM8lsjr6BqBZCx37wB2mtkHILGUo5ktT24u5w9z1v9pQCW8AiwYsbRiqgvKlwPNyRC4DKhLvt4JlI7Y75fAx5I9H8ys1symn3LVknXUI5BMUmRmI0/ZfJPEX9ffM7MvAXnAPcCLJHoA95nZIeBRYP54F+PuPcnhnr8wsxiJefNTcRfwoJltBjYC25Of12pmvzWzLSTWJf6CmZ0BPJU89dUF3Ag0j/fPIplN01CLBMjMSty9KzmK6DvAq+7+rbDrEhlJp4ZEgvWJ5MXjrSRO+eh8vqQd9QhERLKcegQiIllOQSAikuUUBCIiWU5BICKS5RQEIiJZTkEgIpLl/j/iQKvCSm+IkAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "bloc1r9wVBQC",
        "outputId": "41d812d8-a92d-4068-863c-7a697b3c2997"
      },
      "source": [
        "learner.plot(show_lr=2e-2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2ad0ed3610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "YLuVe7lJVQ2C",
        "outputId": "574cad55-f76e-414b-ed30-c32d73696763"
      },
      "source": [
        "learner.fit(epochs=6, lr=6e-5, validate=True, schedule_type=\"warmup_cosine\", optimizer_type=\"lamb\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [2/2 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [2/2 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [2/2 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [2/2 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [2/2 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [2/2 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 0.7175382659548805)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jkF2vhIVvRm"
      },
      "source": [
        "learner.save_model()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBeaXfKAV0W4",
        "outputId": "db245956-69b2-4e3d-a12c-7b6ead82a5e4"
      },
      "source": [
        "texts = ['I really love the Netflix original movies',\n",
        "\t\t 'this movie is not worth watching']\n",
        "predictions = learner.predict_batch(texts)\n",
        "predictions"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('1', 0.6220703125), ('0', 0.3779296875)],\n",
              " [('1', 0.69384765625), ('0', 0.306396484375)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in4adgqxYyzk"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "5BahbHhiWKnE",
        "outputId": "1213d938-b098-4a3c-9a08-881b82b83929"
      },
      "source": [
        "from fast_bert.prediction import BertClassificationPredictor\n",
        "\n",
        "MODEL_PATH = 'output/model_out'\n",
        "device_cuda = torch.device(\"cuda\")\n",
        "\n",
        "predictor = BertClassificationPredictor(\n",
        "\t\t\t\tmodel_path=MODEL_PATH,\n",
        "\t\t\t\tlabel_path=LABEL_PATH, # location for labels.csv file\n",
        "\t\t\t\tmulti_label=False,\n",
        "\t\t\t\tmodel_type='xlnet',\n",
        "\t\t\t\tdo_lower_case=False,\n",
        "        device=device_cuda) # set custom torch.device, defaults to cuda if available\n",
        "\n",
        "# Single prediction\n",
        "single_prediction = predictor.predict(\"just get me result for this text\")\n",
        "\n",
        "# Batch predictions\n",
        "texts = [\n",
        "\t\"this is the first text\",\n",
        "\t\"this is the second text\"\n",
        "\t]\n",
        "\n",
        "multiple_predictions = predictor.predict_batch(texts)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-8d7cdcce4cd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                 \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'xlnet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                 \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         device=device_cuda) # set custom torch.device, defaults to cuda if available\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Single prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fast_bert/prediction.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, label_path, multi_label, model_type, use_fast_tokenizer, do_lower_case, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m         )\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fast_bert/prediction.py\u001b[0m in \u001b[0;36mget_learner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mis_fp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mmulti_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mlogging_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         )\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fast_bert/learner_cls.py\u001b[0m in \u001b[0;36mfrom_pretrained_model\u001b[0;34m(dataBunch, pretrained_path, output_dir, metrics, device, logger, finetuned_wgts_path, multi_gpu, is_fp16, loss_scale, warmup_steps, fp16_opt_level, grad_accumulation_steps, multi_label, max_grad_norm, adam_epsilon, logging_steps, freeze_transformer_layers, pos_weight, weight)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fast_bert/learner_cls.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(dataBunch, pretrained_path, finetuned_wgts_path, device, multi_label, pos_weight, weight)\u001b[0m\n\u001b[1;32m    170\u001b[0m         )\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lBPoyXAZpzd"
      },
      "source": [
        "# Language model Databunch\n",
        "from fast_bert.data_lm import BertLMDataBunch\n",
        "# Language model learner\n",
        "from fast_bert.learner_lm import BertLMLearner\n",
        "\n",
        "from pathlib import Path\n",
        "from box import Box"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUyW-F9OZrfW"
      },
      "source": [
        "# Box is a nice wrapper to create an object from a json dict\n",
        "args = Box({\n",
        "    \"seed\": 42,\n",
        "    \"task_name\": 'imdb_reviews_lm',\n",
        "    \"model_name\": 'roberta-base',\n",
        "    \"model_type\": 'roberta',\n",
        "    \"train_batch_size\": 16,\n",
        "    \"learning_rate\": 4e-5,\n",
        "    \"num_train_epochs\": 20,\n",
        "    \"fp16\": True,\n",
        "    \"fp16_opt_level\": \"O2\",\n",
        "    \"warmup_steps\": 1000,\n",
        "    \"logging_steps\": 0,\n",
        "    \"max_seq_length\": 512,\n",
        "    \"multi_gpu\": True if torch.cuda.device_count() > 1 else False\n",
        "})\n",
        "\n",
        "DATA_PATH = Path('../lm_data/')\n",
        "LOG_PATH = Path('../logs')\n",
        "MODEL_PATH = Path('../lm_model_{}/'.format(args.model_type))\n",
        "\n",
        "DATA_PATH.mkdir(exist_ok=True)\n",
        "MODEL_PATH.mkdir(exist_ok=True)\n",
        "LOG_PATH.mkdir(exist_ok=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "XWEDLFKlZv1Y",
        "outputId": "07f52650-0868-4847-c44b-236db5d8a77e"
      },
      "source": [
        "databunch_lm = BertLMDataBunch.from_raw_corpus(\n",
        "\t\t\t\t\tdata_dir=DATA_PATH,\n",
        "\t\t\t\t\ttext_list=texts,\n",
        "\t\t\t\t\ttokenizer=args.model_name,\n",
        "\t\t\t\t\tbatch_size_per_gpu=args.train_batch_size,\n",
        "\t\t\t\t\tmax_seq_length=args.max_seq_length,\n",
        "                    multi_gpu=args.multi_gpu,\n",
        "                    model_type=args.model_type,\n",
        "                    logger=logger)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [1/1 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [1/1 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4193e7fcb9f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mmulti_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     logger=logger)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fast_bert/data_lm.py\u001b[0m in \u001b[0;36mfrom_raw_corpus\u001b[0;34m(data_dir, text_list, tokenizer, batch_size_per_gpu, max_seq_length, multi_gpu, test_size, model_type, logger, clear_cache, no_cache)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mclear_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mno_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         )\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fast_bert/data_lm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, tokenizer, train_file, val_file, batch_size_per_gpu, max_seq_length, multi_gpu, model_type, logger, clear_cache, no_cache)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size_per_gpu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mtrain_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             self.train_dl = DataLoader(\n\u001b[1;32m    288\u001b[0m                 \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m--> 104\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbK0rHzEZ0ZY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}